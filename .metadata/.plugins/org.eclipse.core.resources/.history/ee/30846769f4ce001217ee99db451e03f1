package edu.brown.cs.ai.experiments.planning.fourrooms;

import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

import edu.brown.cs.ai.behavior.oomdp.optiondiscovery.macros.AllSequenceExtraction;
import edu.brown.cs.ai.behavior.oomdp.options.MacroAction;
import edu.brown.cs.ai.behavior.oomdp.options.OptionEvaluatingRF;
import edu.brown.cs.ai.behavior.oomdp.planning.StateConditionTest;
import edu.brown.cs.ai.behavior.oomdp.planning.deterministc.DeterministicPlanner;
import edu.brown.cs.ai.behavior.oomdp.planning.deterministc.SDPlannerPolicy;
import edu.brown.cs.ai.behavior.oomdp.planning.deterministc.SinglePFTF;
import edu.brown.cs.ai.behavior.oomdp.planning.deterministc.TFGoalCondition;
import edu.brown.cs.ai.behavior.oomdp.planning.deterministc.UniformCostRF;
import edu.brown.cs.ai.behavior.oomdp.planning.deterministc.uninformed.dfs.DFS;
import edu.brown.cs.ai.domain.oomdp.fourrooms.FourRoomsDomain;
import edu.umbc.cs.maple.behavior.oomdp.Policy;
import edu.umbc.cs.maple.oomdp.Attribute;
import edu.umbc.cs.maple.oomdp.Domain;
import edu.umbc.cs.maple.oomdp.RewardFunction;
import edu.umbc.cs.maple.oomdp.State;
import edu.umbc.cs.maple.oomdp.TerminalFunction;

public class FourRoomsMacrosExp {

	Domain 									d;
	Map <String, List<Attribute>> 			attributesForHashCode;
	TerminalFunction 						tf;
	StateConditionTest						gc;
	RewardFunction							rf;
	
	/**
	 * @param args
	 */
	public static void main(String[] args) {
		
		FourRoomsMacrosExp exp = new FourRoomsMacrosExp();
		List <MacroAction> noMacros = new ArrayList<MacroAction>();
		List <MacroAction> curMacros = exp.getMacroActionsFor(1, 11, 6, 9, 10, noMacros);
		System.out.println("------------------");
		curMacros = exp.getMacroActionsFor(1, 11, 6, 9, 10, curMacros);
		
		
		//exp.getMacroActionsFor(1, 11, 5, 5, 14, noMacros);
		//List <MacroAction> curMacros = exp.getMacroActionsFor(1, 11, 11, 1, noMacros);

	}
	
	public FourRoomsMacrosExp(){
	
		d = (new FourRoomsDomain()).generateDomain();
		
		attributesForHashCode = new HashMap<String, List<Attribute>>();
		
		List <Attribute> agentAtts = new ArrayList<Attribute>();
		agentAtts.add(d.getAttribute(FourRoomsDomain.ATTX));
		agentAtts.add(d.getAttribute(FourRoomsDomain.ATTY));
		attributesForHashCode.put(FourRoomsDomain.CLASSAGENT, agentAtts);
		
		List <Attribute> goalAtts = new ArrayList<Attribute>(agentAtts);
		attributesForHashCode.put(FourRoomsDomain.CLASSGOAL, goalAtts);
		
		tf = new SinglePFTF(d.getPropFunction(FourRoomsDomain.PFATGOAL));
		gc = new TFGoalCondition(tf);
		rf = new OptionEvaluatingRF(new UniformCostRF());
		
	}
	
	
	public List <MacroAction> getLatestMacroSequences(int ax, int ay, int gx, int gy, int depth, List<MacroAction> existingMacros){
		
		State s = FourRoomsDomain.getCleanState();
		FourRoomsDomain.setAgent(s, ax, ay);
		FourRoomsDomain.setGoal(s, gx, gy);
		
		Policy p = this.getPlan(s, depth, existingMacros);
		
		List <MacroAction> res = new ArrayList<MacroAction>(1);
		
		res.add(AllSequenceExtraction.extractLastPrimitiveSetMacro(s, p, tf, "M" + existingMacros.size()));
		
		return res;
		
	}
	
	public List<MacroAction> getMacroActionsFor(int ax, int ay, int gx, int gy, int depth, List<MacroAction> existingMacros){
		
		State s = FourRoomsDomain.getCleanState();
		FourRoomsDomain.setAgent(s, ax, ay);
		FourRoomsDomain.setGoal(s, gx, gy);
		
		Policy p = this.getPlan(s, depth, existingMacros);
		
		
		return AllSequenceExtraction.getAllMacroSubsequences(7, 7, s, p, tf);
	}
	
	
	public Policy getPlan(State s, int depth, List<MacroAction> existingMacros){
		
		DFS planner = new DFS(d, rf, gc, attributesForHashCode, depth, false, true);
		Policy p = new SDPlannerPolicy((DeterministicPlanner)planner);
		
		for(MacroAction ma : existingMacros){
			planner.addNonDomainReferencedAction(ma);
		}
		
		planner.planFromState(s);
		
		
		return p;
	}

}
